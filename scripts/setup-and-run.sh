#!/bin/bash

# ============================================
# Script de Setup et Ex√©cution - Maritime Tracking
# ============================================

set -e  # Arr√™t en cas d'erreur

echo "============================================"
echo "üö¢ Maritime Tracking System - Setup"
echo "============================================"

# Couleurs pour les messages
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ============================================
# 1. V√âRIFICATION DES PR√âREQUIS
# ============================================
echo -e "\n${BLUE}[1/9]${NC} V√©rification des pr√©requis..."

if ! command -v docker &> /dev/null; then
    echo -e "${RED}‚úó Docker n'est pas install√©${NC}"
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo -e "${RED}‚úó Docker Compose n'est pas install√©${NC}"
    exit 1
fi

echo -e "${GREEN}‚úì Docker et Docker Compose sont install√©s${NC}"

# ============================================
# 2. CR√âATION DE LA STRUCTURE DU PROJET
# ============================================
echo -e "\n${BLUE}[2/9]${NC} Cr√©ation de la structure du projet..."

mkdir -p scala-app/src/main/scala/maritime
mkdir -p scala-app/project
mkdir -p scripts
mkdir -p sql
mkdir -p notebooks
mkdir -p data
mkdir -p config/kafka
mkdir -p config/spark

echo -e "${GREEN}‚úì Structure cr√©√©e${NC}"

# ============================================
# 3. CR√âATION DES FICHIERS DE CONFIGURATION
# ============================================
echo -e "\n${BLUE}[3/9]${NC} Cr√©ation des fichiers de configuration..."

# V√©rifier si les fichiers de config existent d√©j√†
if [ ! -f "hive-site.xml" ]; then
    echo -e "${YELLOW}‚ö†Ô∏è  hive-site.xml manquant - veuillez le cr√©er${NC}"
fi

if [ ! -f "init-hive-db.sh" ]; then
    echo -e "${YELLOW}‚ö†Ô∏è  init-hive-db.sh manquant - veuillez le cr√©er${NC}"
fi

# Rendre les scripts ex√©cutables
chmod +x init-hive-db.sh 2>/dev/null || true
chmod +x init-hive-schema.sh 2>/dev/null || true

cat > scala-app/project/build.properties << 'EOF'
sbt.version=1.9.7
EOF

cat > scala-app/project/plugins.sbt << 'EOF'
addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "2.1.5")
EOF

echo -e "${GREEN}‚úì Configuration cr√©√©e${NC}"

# ============================================
# 4. NETTOYAGE DES CONTENEURS EXISTANTS (OPTIONNEL)
# ============================================
echo -e "\n${BLUE}[4/9]${NC} Nettoyage des conteneurs existants..."

if docker ps -a | grep -q "hive-metastore\|postgres-hive"; then
    echo -e "${YELLOW}‚ö†Ô∏è  Arr√™t des conteneurs Hive existants...${NC}"
    docker-compose stop hive-metastore postgres-hive 2>/dev/null || true
    sleep 5
fi

echo -e "${GREEN}‚úì Nettoyage effectu√©${NC}"

# ============================================
# 5. D√âMARRAGE DES CONTENEURS DOCKER
# ============================================
echo -e "\n${BLUE}[5/9]${NC} D√©marrage des conteneurs Docker..."
echo -e "${YELLOW}‚ö† Cela peut prendre plusieurs minutes...${NC}"

# D√©marrer PostgreSQL en premier
echo "D√©marrage de PostgreSQL..."
docker-compose up -d postgres-hive

# Attendre que PostgreSQL soit pr√™t
echo -n "Attente de PostgreSQL "
for i in {1..30}; do
    if docker exec postgres-hive pg_isready -U hive -d metastore &>/dev/null; then
        echo -e " ${GREEN}‚úì${NC}"
        break
    fi
    echo -n "."
    sleep 2
done

# D√©marrer les autres services
echo "D√©marrage des autres services..."
docker-compose up -d

echo -e "${GREEN}‚úì Conteneurs d√©marr√©s${NC}"

# ============================================
# 6. ATTENTE QUE LES SERVICES SOIENT PR√äTS
# ============================================
echo -e "\n${BLUE}[6/9]${NC} Attente du d√©marrage des services..."

# Fonction pour attendre qu'un conteneur soit en √©tat "running"
wait_for_container() {
    local container=$1
    local max_attempts=30
    local attempt=1
    
    echo -n "Attente de $container "
    while [ $attempt -le $max_attempts ]; do
        if [ "$(docker inspect -f '{{.State.Running}}' $container 2>/dev/null)" == "true" ]; then
            echo -e " ${GREEN}‚úì${NC}"
            return 0
        fi
        echo -n "."
        sleep 2
        attempt=$((attempt + 1))
    done
    echo -e " ${YELLOW}‚ö† Timeout${NC}"
    return 0
}

# V√©rification des conteneurs
wait_for_container "zookeeper"
wait_for_container "kafka"
wait_for_container "namenode"
wait_for_container "datanode"
wait_for_container "spark-master"
wait_for_container "spark-worker"

# Attente suppl√©mentaire pour que les services soient vraiment pr√™ts
echo -e "\n${YELLOW}‚è≥ Attente suppl√©mentaire pour la stabilisation des services (30s)...${NC}"
sleep 30

echo -e "${GREEN}‚úì Services en cours d'ex√©cution${NC}"

# ============================================
# 7. INITIALISATION DU SCH√âMA HIVE
# ============================================
echo -e "\n${BLUE}[7/9]${NC} Initialisation du sch√©ma Hive Metastore..."

# V√©rifier si Hive Metastore est d√©marr√©
wait_for_container "hive-metastore"

# Attendre que le service soit vraiment pr√™t
echo "‚è≥ Attente du d√©marrage complet de Hive Metastore (20s)..."
sleep 20

# V√©rifier si le sch√©ma existe
echo "üîç V√©rification du sch√©ma Hive..."
SCHEMA_EXISTS=$(docker exec postgres-hive psql -U hive -d metastore -tAc "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='public' AND table_name='VERSION';" 2>/dev/null || echo "0")

if [ "$SCHEMA_EXISTS" = "0" ]; then
    echo "üì• Initialisation du sch√©ma Hive (cela peut prendre 1-2 minutes)..."
    
    # Initialiser le sch√©ma
    if docker exec hive-metastore /opt/hive/bin/schematool -dbType postgres -initSchema 2>&1 | tee /tmp/hive-init.log; then
        echo -e "${GREEN}‚úÖ Sch√©ma Hive initialis√© avec succ√®s${NC}"
    else
        echo -e "${YELLOW}‚ö†Ô∏è  √âchec de l'initialisation, tentative de upgrade...${NC}"
        docker exec hive-metastore /opt/hive/bin/schematool -dbType postgres -upgradeSchema
        echo -e "${GREEN}‚úÖ Sch√©ma Hive upgrad√© avec succ√®s${NC}"
    fi
else
    echo -e "${GREEN}‚úÖ Sch√©ma Hive d√©j√† existant${NC}"
fi

# V√©rifier l'√©tat de Hive Metastore
echo "üîç V√©rification de l'√©tat de Hive Metastore..."
docker exec hive-metastore /opt/hive/bin/schematool -dbType postgres -info || echo -e "${YELLOW}‚ö†Ô∏è  Impossible de r√©cup√©rer les infos du sch√©ma${NC}"

echo -e "${GREEN}‚úì Hive Metastore configur√©${NC}"

# ============================================
# 8. CR√âATION DES TOPICS KAFKA
# ============================================
echo -e "\n${BLUE}[8/9]${NC} Cr√©ation des topics Kafka..."

# Attendre que Kafka soit vraiment pr√™t
echo -n "V√©rification de Kafka "
for i in {1..15}; do
    if docker exec kafka kafka-topics --list --bootstrap-server localhost:9092 &>/dev/null; then
        echo -e " ${GREEN}‚úì${NC}"
        break
    fi
    echo -n "."
    sleep 2
done

# Cr√©er les topics
docker exec kafka kafka-topics --create \
    --bootstrap-server localhost:9092 \
    --replication-factor 1 \
    --partitions 3 \
    --topic maritime-tracking \
    --if-not-exists 2>/dev/null || echo -e "${YELLOW}Topic maritime-tracking existe d√©j√†${NC}"

docker exec kafka kafka-topics --create \
    --bootstrap-server localhost:9092 \
    --replication-factor 1 \
    --partitions 1 \
    --topic maritime-alerts \
    --if-not-exists 2>/dev/null || echo -e "${YELLOW}Topic maritime-alerts existe d√©j√†${NC}"

echo -e "${GREEN}‚úì Topics Kafka cr√©√©s${NC}"

# Liste des topics
echo -e "\n${YELLOW}Topics disponibles:${NC}"
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092 2>/dev/null || echo "Kafka pas encore pr√™t"

# ============================================
# 9. CR√âATION DES R√âPERTOIRES HDFS
# ============================================
echo -e "\n${BLUE}[9/9]${NC} Configuration HDFS..."

# Attendre que HDFS soit pr√™t
echo -n "V√©rification de HDFS "
for i in {1..15}; do
    if docker exec namenode hdfs dfs -ls / &>/dev/null; then
        echo -e " ${GREEN}‚úì${NC}"
        break
    fi
    echo -n "."
    sleep 2
done

# Cr√©er les r√©pertoires
docker exec namenode hdfs dfs -mkdir -p /maritime 2>/dev/null || true
docker exec namenode hdfs dfs -mkdir -p /maritime/raw_data 2>/dev/null || true
docker exec namenode hdfs dfs -mkdir -p /maritime/aggregated 2>/dev/null || true
docker exec namenode hdfs dfs -mkdir -p /maritime/anomalies 2>/dev/null || true
docker exec namenode hdfs dfs -mkdir -p /maritime/eta_predictions 2>/dev/null || true
docker exec namenode hdfs dfs -mkdir -p /maritime/analysis 2>/dev/null || true
docker exec namenode hdfs dfs -mkdir -p /maritime/checkpoints 2>/dev/null || true
docker exec namenode hdfs dfs -mkdir -p /user/hive/warehouse 2>/dev/null || true

docker exec namenode hdfs dfs -chmod -R 777 /maritime 2>/dev/null || true
docker exec namenode hdfs dfs -chmod -R 777 /user/hive 2>/dev/null || true

echo -e "${GREEN}‚úì R√©pertoires HDFS cr√©√©s${NC}"

# ============================================
# 10. AFFICHAGE DES INFORMATIONS
# ============================================
echo -e "\n${BLUE}[10/10]${NC} R√©sum√© de l'installation"

echo -e "\n${GREEN}============================================"
echo -e "‚úÖ INSTALLATION TERMIN√âE AVEC SUCC√àS!"
echo -e "============================================${NC}"

echo -e "\nüìä ${YELLOW}Services disponibles:${NC}"
echo -e "  ‚Ä¢ HDFS Web UI:        ${GREEN}http://localhost:9870${NC}"
echo -e "  ‚Ä¢ Spark Master UI:    ${GREEN}http://localhost:8080${NC}"
echo -e "  ‚Ä¢ Spark Worker UI:    ${GREEN}http://localhost:8081${NC}"
echo -e "  ‚Ä¢ Spark Jobs UI:      ${GREEN}http://localhost:4040${NC} (apr√®s d√©marrage job)"
echo -e "  ‚Ä¢ Jupyter Notebook:   ${GREEN}http://localhost:8888${NC}"
echo -e "  ‚Ä¢ PostgreSQL:         ${GREEN}localhost:5432${NC} (user: hive, db: metastore)"

echo -e "\nüîç ${YELLOW}V√©rification de l'√©tat des services:${NC}"
docker-compose ps

echo -e "\nüöÄ ${YELLOW}Prochaines √©tapes:${NC}"
echo -e "  1. Compiler le code Scala:"
echo -e "     ${GREEN}cd scala-app && sbt clean compile assembly${NC}"
echo -e ""
echo -e "  2. Lancer le producer Kafka:"
echo -e "     ${GREEN}./scripts/run-producer.sh${NC}"
echo -e ""
echo -e "  3. Lancer Spark Streaming:"
echo -e "     ${GREEN}./scripts/run-streaming.sh${NC}"
echo -e ""
echo -e "  4. Lancer l'analyse batch:"
echo -e "     ${GREEN}./scripts/run-batch.sh${NC}"

echo -e "\nüìù ${YELLOW}Commandes utiles:${NC}"
echo -e "  ‚Ä¢ Voir les logs:          ${GREEN}docker-compose logs -f [service]${NC}"
echo -e "  ‚Ä¢ Logs Hive:              ${GREEN}docker-compose logs -f hive-metastore${NC}"
echo -e "  ‚Ä¢ Logs PostgreSQL:        ${GREEN}docker-compose logs -f postgres-hive${NC}"
echo -e "  ‚Ä¢ Arr√™ter tout:           ${GREEN}docker-compose down${NC}"
echo -e "  ‚Ä¢ Red√©marrer:             ${GREEN}docker-compose restart${NC}"
echo -e "  ‚Ä¢ Voir HDFS:              ${GREEN}docker exec namenode hdfs dfs -ls /maritime${NC}"
echo -e "  ‚Ä¢ Tester Kafka:           ${GREEN}docker exec kafka kafka-topics --list --bootstrap-server localhost:9092${NC}"
echo -e "  ‚Ä¢ Tester PostgreSQL:      ${GREEN}docker exec postgres-hive psql -U hive -d metastore -c '\dt'${NC}"
echo -e "  ‚Ä¢ Info sch√©ma Hive:       ${GREEN}docker exec hive-metastore /opt/hive/bin/schematool -dbType postgres -info${NC}"

echo -e "\n${BLUE}============================================${NC}"
echo -e "Pour plus d'aide, consultez le README.md"
echo -e "${BLUE}============================================${NC}\n"